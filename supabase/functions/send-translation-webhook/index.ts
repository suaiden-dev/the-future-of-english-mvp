import { createClient } from "npm:@supabase/supabase-js@2";

const corsHeaders = {
  "Access-Control-Allow-Origin": "*",
  "Access-Control-Allow-Methods": "POST, OPTIONS",
  "Access-Control-Allow-Headers": "Content-Type, Authorization",
};

// Cache para evitar processamento duplicado (backup)
const processedRequests = new Map<string, number>();

Deno.serve(async (req: Request) => {
  console.log(`[${new Date().toISOString()}] Edge Function: send-translation-webhook called`);
  console.log(`Method: ${req.method}`);
  console.log(`URL: ${req.url}`);

  // Handle CORS preflight
  if (req.method === "OPTIONS") {
    console.log("Handling CORS preflight request");
    return new Response(null, {
      status: 200,
      headers: corsHeaders,
    });
  }

  if (req.method !== "POST") {
    console.log(`Method ${req.method} not allowed`);
    return new Response("Method Not Allowed", {
      status: 405,
      headers: corsHeaders,
    });
  }

  try {
    // Create Supabase client with service role key
    const supabaseUrl = Deno.env.get("SUPABASE_URL");
    const supabaseServiceKey = Deno.env.get("SUPABASE_SERVICE_ROLE_KEY");
    
    console.log("Supabase URL:", supabaseUrl ? "‚úì Set" : "‚úó Missing");
    console.log("Service Role Key:", supabaseServiceKey ? "‚úì Set" : "‚úó Missing");

    if (!supabaseUrl || !supabaseServiceKey) {
      throw new Error("Missing Supabase environment variables");
    }

    const supabase = createClient(supabaseUrl, supabaseServiceKey);

    // Parse request body
    const requestBody = await req.text();
    console.log("=== WEBHOOK CALL START ===");
    console.log("Timestamp:", new Date().toISOString());
    console.log("Raw request body:", requestBody);
    
    const parsedBody = JSON.parse(requestBody);
    console.log("Parsed request body:", parsedBody);
    console.log("Request headers:", Object.fromEntries(req.headers.entries()));

    // Log adicional para identificar a fonte da chamada
    const referer = req.headers.get('referer') || 'unknown';
    const origin = req.headers.get('origin') || 'unknown';
    console.log("=== REQUEST SOURCE INFO ===");
    console.log("Referer:", referer);
    console.log("Origin:", origin);
    console.log("User-Agent:", req.headers.get('user-agent') || 'unknown');

    // Gerar um ID √∫nico para esta requisi√ß√£o baseado no conte√∫do (SEM timestamp para detectar duplicatas reais)
    const requestId = `${parsedBody.user_id || 'unknown'}_${parsedBody.filename || 'unknown'}`;
    console.log("Request ID:", requestId);
    
    // üîç VERIFICA√á√ÉO ROBUSTA ANTI-DUPLICATA USANDO BANCO DE DADOS
    // Esta √© a solu√ß√£o principal - verificar no banco se j√° existe documento recente
    if (parsedBody.user_id && parsedBody.filename) {
      console.log("üîç VERIFICA√á√ÉO ANTI-DUPLICATA: Checando banco de dados...");
      
      const cutoffTime = new Date(Date.now() - 2 * 60 * 1000).toISOString(); // 2 minutos atr√°s
      
      const { data: recentDocs, error: recentError } = await supabase
        .from('documents_to_be_verified')
        .select('id, filename, created_at')
        .eq('user_id', parsedBody.user_id)
        .eq('filename', parsedBody.filename)
        .gte('created_at', cutoffTime)
        .order('created_at', { ascending: false })
        .limit(1);

      if (recentError) {
        console.log("‚ö†Ô∏è Erro ao verificar duplicatas:", recentError);
      } else if (recentDocs && recentDocs.length > 0) {
        console.log("üö® DUPLICATA DETECTADA! Documento j√° processado recentemente:");
        console.log("Documento existente:", recentDocs[0]);
        console.log("‚è±Ô∏è Criado em:", recentDocs[0].created_at);
        console.log("‚úÖ IGNORANDO upload duplicado para prevenir m√∫ltiplos documentos");
        
        return new Response(
          JSON.stringify({
            success: true,
            status: 200,
            message: "Document already processed recently - duplicate prevented",
            existing_document: recentDocs[0],
            timestamp: new Date().toISOString()
          }),
          {
            status: 200,
            headers: {
              "Content-Type": "application/json",
              ...corsHeaders,
            },
          }
        );
      } else {
        console.log("‚úÖ Nenhuma duplicata encontrada, prosseguindo com o upload");
      }
    }
    
    // Cache em mem√≥ria como backup (pode n√£o funcionar com m√∫ltiplas inst√¢ncias)
    const now = Date.now();
    const lastProcessed = processedRequests.get(requestId);
    if (lastProcessed && (now - lastProcessed) < 120000) {
      console.log("üîÑ Cache em mem√≥ria detectou duplicata");
      return new Response(
        JSON.stringify({
          success: true,
          status: 200,
          message: "Request already processed (memory cache)",
          timestamp: new Date().toISOString()
        }),
        {
          status: 200,
          headers: {
            "Content-Type": "application/json",
            ...corsHeaders,
          },
        }
      );
    }
    
    // Marcar esta requisi√ß√£o como processada
    processedRequests.set(requestId, now);
    
    // Limpar cache antigo (mais de 5 minutos)
    for (const [key, timestamp] of processedRequests.entries()) {
      if (now - timestamp > 300000) { // 5 minutos
        processedRequests.delete(key);
      }
    }

    // Recebe o evento do Supabase Storage ou do frontend
    const { 
      filename, 
      url, 
      mimetype, 
      size, 
      record, 
      user_id, 
      pages,
      paginas,
      document_type,
      tipo_trad, 
      total_cost,
      valor, 
      source_language,
      target_language,
      idioma_raiz, 
      is_bank_statement, 
      client_name 
    } = parsedBody;
    let payload;

    if (record) {
      // Called from Storage trigger
      console.log("Processing storage trigger payload");
      const bucket = record.bucket_id || record.bucket || record.bucketId;
      const path = record.name || record.path || record.file_name;
      
      // Corrigir a gera√ß√£o da URL p√∫blica
      let publicUrl;
      if (url && url.startsWith('http')) {
        // Se j√° temos uma URL v√°lida, usar ela
        publicUrl = url;
      } else {
        // Gerar URL p√∫blica corretamente
        const { data: { publicUrl: generatedUrl } } = supabase.storage
          .from(bucket || 'documents')
          .getPublicUrl(path);
        publicUrl = generatedUrl;
      }
      
      console.log("Generated public URL:", publicUrl);
      
      payload = {
        filename: path,
        url: publicUrl,
        mimetype: record.mimetype || record.metadata?.mimetype || "application/octet-stream",
        size: record.size || record.metadata?.size || null,
        user_id: record.user_id || record.metadata?.user_id || null,
        // üéØ USAR CAMPOS EXATOS QUE O N8N ESPERA (como funcionava antes)
        paginas: record.pages || pages || paginas || 1,                                              // "paginas" ‚úÖ
        tipo_trad: record.document_type || document_type || record.tipo_trad || tipo_trad || 'Certificado',  // "tipo_trad" ‚úÖ  
        valor: record.total_cost || total_cost || record.valor || valor || 0,                                 // "valor" ‚úÖ
        idioma_raiz: record.source_language || source_language || record.idioma_raiz || idioma_raiz || 'Portuguese',  // "idioma_raiz" ‚úÖ
        is_bank_statement: record.is_bank_statement || is_bank_statement || false,
        client_name: record.client_name || client_name || null,
        // Adicionar informa√ß√µes sobre o tipo de arquivo
        isPdf: (record.mimetype || record.metadata?.mimetype || "application/octet-stream") === 'application/pdf',
        fileExtension: path.split('.').pop()?.toLowerCase(),
        // Informar ao n8n que deve usar a tabela 'profiles' em vez de 'users'
        tableName: 'profiles',
        schema: 'public'
      };
    } else {
      // Called from frontend
      console.log("Processing frontend payload");
      console.log("URL received:", url);
      console.log("User ID:", user_id);
      console.log("Filename:", filename);
      
      // Verificar se a URL j√° √© v√°lida
      let finalUrl = url;
      if (url && !url.startsWith('http')) {
        // Se a URL n√£o √© completa, tentar gerar uma URL p√∫blica
        try {
          // Extrair o caminho do arquivo da URL
          const urlParts = url.split('/');
          const fileName = urlParts[urlParts.length - 1];
          const userFolder = urlParts[urlParts.length - 2];
          const filePath = `${userFolder}/${fileName}`;
          
          console.log("Extracted file path:", filePath);
          
          const { data: { publicUrl: generatedUrl } } = supabase.storage
            .from('documents')
            .getPublicUrl(filePath);
          
          finalUrl = generatedUrl;
          console.log("Generated public URL from path:", finalUrl);
        } catch (urlError) {
          console.error("Error generating public URL:", urlError);
          // Usar a URL original se n√£o conseguir gerar
          finalUrl = url;
        }
      }
      
      payload = { 
        filename: filename, 
        url: finalUrl, 
        mimetype, 
        size, 
        user_id: user_id || null, 
        // üéØ USAR CAMPOS EXATOS QUE O N8N ESPERA (como funcionava antes)
        paginas: pages || paginas || 1,                              // "paginas" ‚úÖ
        tipo_trad: document_type || tipo_trad || 'Certificado',      // "tipo_trad" ‚úÖ
        valor: total_cost || valor || 0,                             // "valor" ‚úÖ
        idioma_raiz: source_language || idioma_raiz || 'Portuguese', // "idioma_raiz" ‚úÖ
        is_bank_statement: is_bank_statement || false,
        client_name: client_name || null,
        // Adicionar informa√ß√µes sobre o tipo de arquivo
        isPdf: mimetype === 'application/pdf',
        fileExtension: filename.split('.').pop()?.toLowerCase(),
        // Informar ao n8n que deve usar a tabela 'profiles' em vez de 'users'
        tableName: 'profiles',
        schema: 'public'
      };
      
      console.log("Final payload for frontend:", JSON.stringify(payload, null, 2));
    }

    console.log("Final payload for n8n webhook:", JSON.stringify(payload, null, 2));

    // Verificar se o arquivo √© um PDF antes de enviar para o n8n
    const isPdf = payload.isPdf || payload.mimetype === 'application/pdf' || payload.filename.toLowerCase().endsWith('.pdf');
    console.log("Is PDF file:", isPdf);
    console.log("File mimetype:", payload.mimetype);
    console.log("File extension:", payload.fileExtension);
    console.log("Table name for n8n:", payload.tableName);

    // Send POST to n8n webhook
    const webhookUrl = "https://nwh.thefutureofenglish.com/webhook/tfoetranslations";
    console.log("Sending webhook to:", webhookUrl);
    console.log("Payload being sent to n8n:", JSON.stringify(payload, null, 2));

    const webhookResponse = await fetch(webhookUrl, {
      method: "POST",
      headers: { 
        "Content-Type": "application/json",
        "User-Agent": "Supabase-Edge-Function/1.0"
      },
      body: JSON.stringify(payload),
    });
    const responseText = await webhookResponse.text();
    console.log("n8n webhook response status:", webhookResponse.status);
    console.log("n8n webhook response headers:", Object.fromEntries(webhookResponse.headers.entries()));
    console.log("n8n webhook response body:", responseText);

    // If webhook call was successful and we have user_id, update document status
    if (webhookResponse.ok && user_id && filename) {
      try {
        console.log("Updating document status to processing...");
        console.log("Looking for document with user_id:", user_id, "and filename:", filename);
        
        const { data: updateData, error: updateError } = await supabase
          .from('documents')
          .update({ status: 'processing' })
          .eq('user_id', user_id)
          .eq('filename', filename)
          .select();
        
        if (updateError) {
          console.error("Error updating document status:", updateError);
        } else {
          console.log("Document status updated successfully:", updateData);
        }
      } catch (updateError) {
        console.error("Exception updating document status:", updateError);
      }
    }

    // üìã FLUXO H√çBRIDO: Enviar para n8n E inserir na tabela documents_to_be_verified
    // Isso garante que o valor seja registrado mesmo para tradu√ß√µes gratuitas
    if (webhookResponse.ok && user_id && url) {
      try {
        console.log("=== INSER√á√ÉO EM DOCUMENTS_TO_BE_VERIFIED ===");
        console.log("user_id:", user_id);
        console.log("filename:", filename);
        
        // Buscar dados do documento para pegar informa√ß√µes completas
        const { data: docData, error: docError } = await supabase
          .from('documents')
          .select('id, total_cost, document_type, source_language, is_bank_statement, pages, client_name')
          .eq('user_id', user_id)
          .eq('filename', filename)
          .single();

        if (docData && !docError) {
          console.log("Found document data:", docData);
          
          // Verifica√ß√£o final contra duplicatas ANTES da inser√ß√£o
          const { data: finalCheck, error: finalCheckError } = await supabase
            .from('documents_to_be_verified')
            .select('id, filename, status, created_at')
            .eq('user_id', user_id)
            .eq('filename', filename)
            .limit(1);

          if (finalCheckError) {
            console.error("Error in final duplicate check:", finalCheckError);
          } else if (finalCheck && finalCheck.length > 0) {
            console.log("üö® FINAL DUPLICATE CHECK: Document already exists in documents_to_be_verified");
            console.log("Existing document:", finalCheck[0]);
            console.log("‚è≠Ô∏è SKIPPING insertion to prevent duplicate");
          } else {
            console.log("‚úÖ Final duplicate check passed - proceeding with insertion");
            
            // üéØ USAR A L√ìGICA DA EDGE FUNCTION ANTIGA (que funcionava!)
            // Pegar o valor original do documento, n√£o calcular baseado em p√°ginas
            const pages = docData.pages || payload.pages || 1;
            const originalValue = docData.total_cost || payload.total_cost || 0;
            
            console.log("üìä VALOR ORIGINAL DO DOCUMENTO (como na Edge Function antiga):");
            console.log("  - P√°ginas:", pages);
            console.log("  - Valor original do documento:", originalValue);
            console.log("  - Valor pago pelo authenticator:", docData.total_cost || payload.total_cost || 0);
            console.log("  - Usando valor original (n√£o calculado) ‚úÖ");
            
            const insertData = {
              user_id: user_id,
              filename: filename,
              pages: pages,
              status: 'pending',
              total_cost: originalValue, // üéØ VALOR ORIGINAL (como funcionava antes)
              is_bank_statement: docData.is_bank_statement || payload.is_bank_statement || false,
              source_language: docData.source_language || payload.source_language || 'portuguese',
              target_language: 'english',
              translation_status: 'pending',
              file_id: docData.id,
              verification_code: `TFEB${Math.random().toString(36).substr(2, 5).toUpperCase()}`,
              client_name: docData.client_name || payload.client_name || null,
              translated_file_url: payload.url
            };
            
            console.log("Attempting to insert data:", JSON.stringify(insertData, null, 2));
            
            const { data: verifyData, error: verifyError } = await supabase
              .from('documents_to_be_verified')
              .insert(insertData)
              .select();

            if (verifyError) {
              console.error("Error inserting into documents_to_be_verified:", verifyError);
              
              // Se o erro for de duplicata, n√£o falhar completamente
              if (verifyError.code === '23505') {
                console.log("üö® DUPLICATE KEY ERROR - Document already exists (this is expected behavior)");
              }
            } else {
              console.log("‚úÖ Inserted into documents_to_be_verified successfully:", verifyData);
              console.log("üí∞ Valor registrado:", insertData.total_cost);
            }
          }
        } else {
          console.error("Error finding document:", docError);
        }
      } catch (verifyError) {
        console.error("Exception inserting into documents_to_be_verified:", verifyError);
      }
    }

    // ‚úÖ Webhook enviado para n8n com sucesso
    if (webhookResponse.ok) {
      console.log("‚úÖ Webhook enviado para n8n com sucesso");
      console.log("üìã Valor da tradu√ß√£o registrado em documents_to_be_verified");
    }

    const responseData = {
      success: webhookResponse.ok,
      status: webhookResponse.status,
      message: responseText,
      payload: payload,
      timestamp: new Date().toISOString()
    };

    console.log("Final response:", JSON.stringify(responseData, null, 2));

    return new Response(
      JSON.stringify(responseData),
      {
        status: webhookResponse.ok ? 200 : 500,
        headers: {
          "Content-Type": "application/json",
          ...corsHeaders,
        },
      }
    );

  } catch (error) {
    console.error("Error in send-translation-webhook:", error);
    console.error("Error stack:", error.stack);
    
    const errorResponse = {
      success: false,
      error: error.message,
      stack: error.stack,
      timestamp: new Date().toISOString()
    };

    return new Response(
      JSON.stringify(errorResponse),
      {
        status: 500,
        headers: {
          "Content-Type": "application/json",
          ...corsHeaders,
        },
      }
    );
  }
});